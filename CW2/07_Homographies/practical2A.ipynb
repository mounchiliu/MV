{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 7 - Part 2A\n",
    "This project explores the geometry of a single camera. The aim is to take several points on\n",
    "a plane, and predict where they will appear in the camera image. Based on these observed\n",
    "points, we will then try to re-estimate the Euclidean transformation relating the plane and\n",
    "the camera. In practical 2B we will use this code to draw a wireframe cube\n",
    "on an augmented reality marker.   You should use this\n",
    "template for your code and fill in the missing sections marked \"TO DO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO - fill in projectiveCamera and estimatePlanePose functions  (you will have to utilise your solutions for solveAXEqualsZero and calcBestHomography from Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The goal of this function is to project points in XCart through projective camera\n",
    "#defined by intrinsic matrix K and extrinsic matrix T.\n",
    "def projectiveCamera(K,T,XCart):\n",
    "    \n",
    "    # TO DO: Replace this\n",
    "    # XImCart =\n",
    "\n",
    "    # TO DO: Convert Cartesian 3d points XCart to homogeneous coordinates XHom\n",
    "    XHom = np.concatenate((XCart, np.ones((1,XCart.shape[1]))), axis=0)\n",
    "    \n",
    "    # TO DO: Apply extrinsic matrix to XHom, to move to frame of reference of camera\n",
    "    XHom_cam = T@XHom\n",
    "    # TO DO: Project points into normalized camera coordinates xCamHom (remove 4th row)\n",
    "    XHom_cam = XHom_cam[0:3,:]\n",
    "    # TO DO: Move points to image coordinates xImHom by applying intrinsic matrix\n",
    "    X_image = K@XHom_cam\n",
    "    # TO DO: Convert points back to Cartesian coordinates xImCart\n",
    "    X_image = X_image[0:2,:] / np.tile([X_image[2,:]],(2,1))\n",
    "    return X_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "The code above is used to map the points to the frame of reference of camera using extrinsic matrix T and project the points to image coordinates using intrinsic matrix K. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveAXEqualsZero(A):\n",
    "    # TO DO: Write this routine - it should solve Ah = 0   \n",
    "    #Compute SVD of matrix A\n",
    "    u, s, vh = np.linalg.svd(A)\n",
    "    #set h to the last column of V\n",
    "    h = vh.T[:,-1]\n",
    "    return h\n",
    "\n",
    "# This function should apply the direct linear transform (DLT) algorithm to calculate the best \n",
    "# homography that maps the points in pts1Cart to their corresonding matching in pts2Cart\n",
    "def calcBestHomography(pts1Cart, pts2Cart):    \n",
    "    # TO DO: replace this\n",
    "    H = np.zeros([3,3])\n",
    "\n",
    "    # TO DO: \n",
    "    # First convert points into homogeneous representation\n",
    "    pts1Hom = np.concatenate((pts1Cart[0:2,:], np.ones((1,pts1Cart.shape[1]))), axis=0)\n",
    "    # Then construct the matrix A, size (n_points,9)  \n",
    "    #map from 2D -> 2D\n",
    "    n_points = pts1Cart.shape[1]\n",
    "    A = np.zeros([2*n_points,9])\n",
    "\n",
    "    #find the matrix relates to X\n",
    "    #pts2Cart - dxn\n",
    "    # value of x in the second coordinate system\n",
    "    coord2_X = np.tile(pts2Cart[0,:],(3,1)).T\n",
    "    # value of y in the second coordinate system\n",
    "    coord2_Y = np.tile(pts2Cart[1,:],(3,1)).T\n",
    "\n",
    "    \n",
    "    #concentrate the matrix\n",
    "    X = np.hstack((pts1Hom.T,np.zeros([n_points,3]),(coord2_X*(-pts1Hom.T))))\n",
    "    Y = np.hstack((np.zeros([n_points,3]),-pts1Hom.T,(coord2_Y*(pts1Hom.T))))\n",
    "    \n",
    "    for i in range(n_points):\n",
    "        indexRelates_y = 2*i\n",
    "        indexRelates_x = 2*i + 1\n",
    "        A[indexRelates_x] = X[i]\n",
    "        A[indexRelates_y] = Y[i]\n",
    "\n",
    "    # Solve Ah = 0\n",
    "    h = solveAXEqualsZero(A)\n",
    "    # Reshape h into the matrix H, values of h go first into rows of H\n",
    "    H = np.reshape(h,H.shape)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal of function is to estimate pose of plane relative to camera (extrinsic matrix)\n",
    "# given points in image xImCart, points in world XCart and intrinsic matrix K\n",
    "\n",
    "def estimatePlanePose(XImCart,XCart,K):\n",
    "\n",
    "    # TO DO: replace this\n",
    "    #T = \n",
    "\n",
    "    # TO DO: Convert Cartesian image points XImCart to homogeneous representation XImHom\n",
    "    XImHom = np.concatenate((XImCart, np.ones((1,XImCart.shape[1]))), axis=0)\n",
    "    \n",
    "    # TO DO: Convert image co-ordinates XImHom to normalized camera coordinates XCamHom    \n",
    "    XCamHom = np.linalg.inv(K)@XImHom\n",
    "    \n",
    "    # TO DO: Estimate homography H mapping homogeneous (x,y) coordinates of positions\n",
    "    # in real world to XCamHom (convert XCamHom to Cartesian, calculate the homography) -\n",
    "    # use the routine you wrote for Practical 1B\n",
    "    XCam = XCamHom[0:2,:] / np.tile([XCamHom[2,:]],(2,1))\n",
    "    H = calcBestHomography(XCart, XCam)   \n",
    "    # TO DO: Estimate first two columns of rotation matrix R from the first two\n",
    "    # columns of H using the SVD       \n",
    "    \n",
    "    # Get first two cols which relates to rotation matrix\n",
    "    H_R = H[:,0:2]\n",
    "    U, L, Vh = np.linalg.svd(H_R)\n",
    "    # chose R_1:2 = UVh\n",
    "    I = np.array([[1,0],[0,1],[0,0]])\n",
    "    R_12 = U@I@Vh\n",
    "    \n",
    "    \n",
    "    # TO DO: Estimate the third column of the rotation matrix by taking the cross\n",
    "    # product of the first two columns\n",
    "    R_3 = np.cross(R_12[:,0],R_12[:,1]).reshape(3,1)\n",
    "    R = np.hstack((R_12,R_3))\n",
    "    \n",
    "        \n",
    "    # TO DO: Check that the determinant of the rotation matrix is positive - if\n",
    "    # not then multiply last column by -1.\n",
    "    det = np.linalg.det(R)\n",
    "    if det <= 0:\n",
    "        R[:,2] *= -1  \n",
    "    \n",
    "    # TO DO: Estimate the translation t by finding the appropriate scaling factor k\n",
    "    # and applying it to the third colulmn of H\n",
    "    k = sum(sum(R[:,0:2]/H[:,0:2]));\n",
    "    t = k*H[:,-1]\n",
    "    t = t/6; #average\n",
    "\n",
    "    # TO DO: Check whether t_z is negative - if it is then multiply t by -1 and\n",
    "    # the first two columns of R by -1.\n",
    "    if t[2]<0:\n",
    "        t=-1*t\n",
    "        R[:,0:2]=-1*R[:,0:2]\n",
    "  \n",
    "    # TO DO: Assemble transformation into matrix form\n",
    "    T = np.hstack((R,t.reshape(3,1)))\n",
    "    temp = np.array([[0,0,0,1]])\n",
    "    T = np.r_[T,temp]\n",
    "    \n",
    "    return T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "The code above is used to find the estimated rotation matrix and translation matrix from the estimated Homography matrix.\n",
    "\n",
    "We have\n",
    "\n",
    "$\\lambda \\begin{bmatrix}\n",
    "        x\\\\ \n",
    "        y\\\\ \n",
    "        1\n",
    "       \\end{bmatrix}\n",
    "       = K\n",
    "       \\begin{bmatrix}\n",
    "        w_{11} & w_{12} & \\tau_{x}\\\\ \n",
    "        w_{21} & w_{22} & \\tau_{y}\\\\ \n",
    "        w_{31} & w_{32} & \\tau_{z}\n",
    "       \\end{bmatrix}\n",
    "       \\begin{bmatrix}\n",
    "        u\\\\ \n",
    "        v\\\\ \n",
    "        1\n",
    "       \\end{bmatrix}\n",
    "       =\n",
    "       \\begin{bmatrix}\n",
    "       \\phi_{11} & \\phi_{12} & \\phi_{13}\\\\ \n",
    "       \\phi_{21} & \\phi_{22} & \\phi_{23}\\\\ \n",
    "       \\phi_{31} & \\phi_{32} & \\phi_{33}\n",
    "       \\end{bmatrix}\n",
    "       \\begin{bmatrix}\n",
    "        u\\\\ \n",
    "        v\\\\ \n",
    "        1\n",
    "       \\end{bmatrix}$\n",
    "\n",
    "where K is the intrinsic matrix of camera.\n",
    "\n",
    "Factor out the intrinsic parameters\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "       \\phi'_{11} & \\phi'_{12} & \\phi'_{13}\\\\ \n",
    "       \\phi'_{21} & \\phi'_{22} & \\phi'_{23}\\\\ \n",
    "       \\phi'_{31} & \\phi'_{32} & \\phi'_{33}\n",
    "\\end{bmatrix}\n",
    "= \\lambda'       \n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{12} & \\tau_{x}\\\\ \n",
    "w_{21} & w_{22} & \\tau_{y}\\\\ \n",
    "w_{31} & w_{32} & \\tau_{z}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "**Rotation Matrix**\n",
    "\n",
    "First, to estimate the first two columns of rotation matrix, we compute \n",
    "\n",
    "$\\begin{bmatrix}\n",
    "       \\phi'_{11} & \\phi'_{12} \\\\ \n",
    "       \\phi'_{21} & \\phi'_{22} \\\\ \n",
    "       \\phi'_{31} & \\phi'_{32}\n",
    "\\end{bmatrix} = ULV^T$ and choose $R'=UV^T$\n",
    "\n",
    "Then, we use the cross product of first two columns to find the last column of the rotation matrix.\n",
    "\n",
    "Furthermore, if the determinant is nagtive, we need to multiply the last column by -1.\n",
    "\n",
    "**Translation Matrix**\n",
    "\n",
    "First, we find the translation scaling factor by using\n",
    "\n",
    "$\\lambda' = \\frac{\\sum_{m=1}^3\\sum_{n=1}^2\\phi'_{mn}/w_{mn}}{6}$\n",
    "\n",
    "Then set the translation matrix to be\n",
    "\n",
    "$\\tau = [\\phi'_{13},\\phi'_{23},\\phi'_{33}]^T/ \\lambda'$\n",
    "\n",
    "The translation matrix is also required to be checked weather tz is negative to ensure the valid transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once you have completed these functions, use them to estimate the transformation from the plane co-ordinate system to the camera co-ordinate system (i.e. the extrinsic matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that the intrinsic camera matrix K is known and has values\n",
    "K = np.array([[640, 0, 320],\n",
    "             [0, 640, 240],\n",
    "             [0, 0, 1]])\n",
    "\n",
    "# We will assume an object co-ordinate system with the Z-axis pointing upwards and the origin\n",
    "# in the centre of the plane. There are four known points on the plane with coordinates (mm):\n",
    "XCart = np.array([[-100, -100,  100,  100, 0],\n",
    "                  [-100,  100,  100, -100, 0],\n",
    "                  [   0,    0,    0,    0, 0]])\n",
    "\n",
    "# We assume the correct transformation from the plane co-ordinate system to the\n",
    "# camera co-ordinate system (extrinsic matrix) is:\n",
    "T = np.array([[0.9851,  -0.0492,  0.1619,  46.00],\n",
    "             [-0.1623,  -0.5520,  0.8181,  70.00],\n",
    "             [0.0490,  -0.8324, -0.5518,  500.89],\n",
    "             [0,        0,       0,       1]])\n",
    "  \n",
    "# TO DO: Use the general pin-hole projective camera model discussed in the lectures to estimate \n",
    "# where the four points on the plane will appear in the image.  Fill in the\n",
    "# details of the function \"projectiveCamera\" - body of function appears below:\n",
    "\n",
    "XImCart =  projectiveCamera(K,T,XCart)\n",
    "\n",
    "# TO DO: Add noise (standard deviation of one pixel in each direction) to the pixel positions\n",
    "# to simulate having to find these points in a noisy image. Store the results back in xImCart\n",
    "\n",
    "\n",
    "# TO DO: Now we will take the image points and the known positions on the card and estimate  \n",
    "# the extrinsic matrix using the algorithm discussed in the lecture.  Fill in the details of \n",
    "# the function \"estimate plane pose\"\n",
    "TEst = estimatePlanePose(XImCart,XCart,K)\n",
    "\n",
    "\n",
    "# If you have got this correct, Test should closely resemble T above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.85520172e-01, -4.93647932e-02,  1.62213157e-01,\n",
       "         4.60524114e+01],\n",
       "       [-1.62275327e-01, -5.51968840e-01,  8.17922440e-01,\n",
       "         7.00797564e+01],\n",
       "       [ 4.91600358e-02, -8.32402256e-01, -5.51987114e-01,\n",
       "         5.01460703e+02],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "The program first uses extrinsic to map points in defined object co-ordinate system to the reference camera coordinates and then use intrinsic matrix to map points to the image coordinates. \n",
    "Then, with the obtained Cartesian coordinates in the image plane and points in the object co-ordinate system, the Homography matrix is calculated. The Homography matrix is used to recover the transformation matrix. As we can see from the result, the estimated transformation matrix closely resembles the defined transformation matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
